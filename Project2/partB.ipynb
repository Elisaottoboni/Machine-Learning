{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Analysis (Identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: Eta=0.001, Lambda=0\n",
      "  [=======================================>] 100.0% | train_error: 2.91  Constant: Eta=0.001, Lambda=0.0001\n",
      "  [=======================================>] 100.0% | train_error: 2.91  \n",
      "Output Skranke Function:\n",
      "OLS MSE:\t7.800420720056626e-30\n",
      "Ridge MSE:\t2.3073444031039592e-08\n",
      "FFNN MSE:\t2.7122725734665996\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Example\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from FFNN_class import *\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "import autograd.numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def SkrankeFunction(x, y):\n",
    "    return np.ravel(0 + 1*x + 2*y + 3*x**2 + 4*x*y + 5*y**2)\n",
    "\n",
    "def create_X(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    l = int((n + 1) * (n + 2) / 2)  # Number of elements in beta\n",
    "    X = np.ones((N, l))\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        q = int((i) * (i + 1) / 2)\n",
    "        for k in range(i + 1):\n",
    "            X[:, q + k] = (x ** (i - k)) * (y**k)\n",
    "\n",
    "    return X\n",
    "\n",
    "step=0.05\n",
    "x = np.arange(0, 1, step)\n",
    "y = np.arange(0, 1, step)\n",
    "x, y = np.meshgrid(x, y)\n",
    "target = SkrankeFunction(x, y)\n",
    "target = target.reshape(target.shape[0], 1)\n",
    "\n",
    "poly_degree=3\n",
    "X = create_X(x, y, poly_degree)\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, target, test_size=0.2)\n",
    "\n",
    "input_nodes = X_train.shape[1]\n",
    "output_nodes = 1\n",
    "\n",
    "linear_regression = FFNN((input_nodes, output_nodes), output_func=identity, cost_func=CostOLS, seed=2023)\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "\n",
    "scheduler = Constant(eta=1e-3)\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler, epochs=500)\n",
    "\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler, lam=1e-4, epochs=500)\n",
    "\n",
    "# OLS using Scikit-Learn\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train, t_train)\n",
    "ols_predictions = ols_model.predict(X_test)\n",
    "ols_mse = mean_squared_error(t_test, ols_predictions)\n",
    "\n",
    "# Ridge using Scikit-Learn\n",
    "ridge_model = Ridge(alpha=1e-4)\n",
    "ridge_model.fit(X_train, t_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(t_test, ridge_predictions)\n",
    "\n",
    "# FFNN predictions\n",
    "ffnn_predictions = linear_regression.predict(X_test)\n",
    "ffnn_mse = mean_squared_error(t_test, ffnn_predictions)\n",
    "\n",
    "print(f'\\nOutput Skranke Function:')\n",
    "print(f\"OLS MSE:\\t{ols_mse}\")\n",
    "print(f\"Ridge MSE:\\t{ridge_mse}\")\n",
    "print(f\"FFNN MSE:\\t{ffnn_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: Eta=0.001, Lambda=0\n",
      "  [=======================================>] 100.0% | train_error: 0.320 Constant: Eta=0.001, Lambda=0.0001\n",
      "  [=======================================>] 100.0% | train_error: 0.0322  \n",
      "Output Franke Function:\n",
      "OLS MSE:\t0.0026093433625198996\n",
      "Ridge MSE:\t0.0035740018146377716\n",
      "FFNN MSE:\t0.04193178879572511\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Franke Function\n",
    "import autograd.numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Franke function\n",
    "np.random.seed(2024)\n",
    "def franke_function(x, y):\n",
    "    term1 = 0.75 * np.exp(-( (9*x - 2)**2 / 4.0 + (9*y - 2)**2 / 4.0))\n",
    "    term2 = 0.75 * np.exp(-( (9*x + 1)**2 / 49.0 + (9*y + 1)**2 / 10.0))\n",
    "    term3 = 0.5 * np.exp(-( (9*x - 7)**2 / 4.0 + (9*y - 3)**2 / 4.0))\n",
    "    term4 = -0.2 * np.exp(-(9*x - 4)**2 - (9*y - 7)**2)\n",
    "    return np.ravel(term1 + term2 + term3 + term4)\n",
    "\n",
    "def create_X(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    l = int((n + 1) * (n + 2) / 2)  # Number of elements in beta\n",
    "    X = np.ones((N, l))\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        q = int((i) * (i + 1) / 2)\n",
    "        for k in range(i + 1):\n",
    "            X[:, q + k] = (x ** (i - k)) * (y**k)\n",
    "\n",
    "    return X\n",
    "\n",
    "step=0.05\n",
    "x = np.arange(0, 1, step)\n",
    "y = np.arange(0, 1, step)\n",
    "x, y = np.meshgrid(x, y)\n",
    "target = franke_function(x, y)\n",
    "target = target.reshape(target.shape[0], 1)\n",
    "\n",
    "poly_degree=5\n",
    "X = create_X(x, y, poly_degree)\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, target, test_size=0.2)\n",
    "\n",
    "input_nodes = X_train.shape[1]\n",
    "output_nodes = 1\n",
    "\n",
    "linear_regression = FFNN((input_nodes, output_nodes), output_func=identity, cost_func=CostOLS, seed=2024)\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "\n",
    "scheduler = Constant(eta=1e-3)\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler)\n",
    "\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler, lam=1e-4, epochs=5000)\n",
    "\n",
    "# OLS using Scikit-Learn\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train, t_train)\n",
    "ols_predictions = ols_model.predict(X_test)\n",
    "ols_mse = mean_squared_error(t_test, ols_predictions)\n",
    "\n",
    "# Ridge using Scikit-Learn\n",
    "ridge_model = Ridge(alpha=1e-4)\n",
    "ridge_model.fit(X_train, t_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(t_test, ridge_predictions)\n",
    "\n",
    "# FFNN predictions\n",
    "ffnn_predictions = linear_regression.predict(X_test)\n",
    "ffnn_mse = mean_squared_error(t_test, ffnn_predictions)\n",
    "\n",
    "print(f'\\nOutput Franke Function:')\n",
    "print(f\"OLS MSE:\\t{ols_mse}\")\n",
    "print(f\"Ridge MSE:\\t{ridge_mse}\")\n",
    "print(f\"FFNN MSE:\\t{ffnn_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Analysis (Sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam: Eta=0.001, Lambda=0\n",
      "  [=======================================>] 100.0% | train_error: 0.734 Adam: Eta=0.001, Lambda=0.0001\n",
      "  [=======================================>] 100.0% | train_error: 0.311  \n",
      "Output Skranke Function:\n",
      "OLS MSE:\t7.800420720056626e-30\n",
      "Ridge MSE:\t2.3073444031039592e-08\n",
      "FFNN MSE:\t0.5118881779724713\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Example\n",
    "np.random.seed(2024)\n",
    "\n",
    "import autograd.numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def SkrankeFunction(x, y):\n",
    "    return np.ravel(0 + 1*x + 2*y + 3*x**2 + 4*x*y + 5*y**2)\n",
    "\n",
    "def create_X(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    l = int((n + 1) * (n + 2) / 2)  # Number of elements in beta\n",
    "    X = np.ones((N, l))\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        q = int((i) * (i + 1) / 2)\n",
    "        for k in range(i + 1):\n",
    "            X[:, q + k] = (x ** (i - k)) * (y**k)\n",
    "\n",
    "    return X\n",
    "\n",
    "step=0.05\n",
    "x = np.arange(0, 1, step)\n",
    "y = np.arange(0, 1, step)\n",
    "x, y = np.meshgrid(x, y)\n",
    "target = SkrankeFunction(x, y)\n",
    "target = target.reshape(target.shape[0], 1)\n",
    "\n",
    "poly_degree=3\n",
    "X = create_X(x, y, poly_degree)\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, target, test_size=0.2)\n",
    "\n",
    "input_nodes = X_train.shape[1]\n",
    "hidden_nodes1 = 500\n",
    "hidden_nodes2 = 250\n",
    "output_nodes = 1\n",
    "\n",
    "dims = (input_nodes, hidden_nodes1, hidden_nodes2, output_nodes)\n",
    "linear_regression = FFNN(dims, hidden_func=sigmoid, output_func=identity, cost_func=CostOLS, seed=2024)\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "\n",
    "scheduler = Adam(eta=1e-3, rho=0.9, rho2=0.999)\n",
    "# scheduler = Constant(eta=1e-3)\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler)\n",
    "\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler, lam=1e-4, epochs=5000)\n",
    "\n",
    "# OLS using Scikit-Learn\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train, t_train)\n",
    "ols_predictions = ols_model.predict(X_test)\n",
    "ols_mse = mean_squared_error(t_test, ols_predictions)\n",
    "\n",
    "# Ridge using Scikit-Learn\n",
    "ridge_model = Ridge(alpha=1e-4)\n",
    "ridge_model.fit(X_train, t_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(t_test, ridge_predictions)\n",
    "\n",
    "# FFNN predictions\n",
    "ffnn_predictions = linear_regression.predict(X_test)\n",
    "ffnn_mse = mean_squared_error(t_test, ffnn_predictions)\n",
    "\n",
    "print(f'\\nOutput Skranke Function:')\n",
    "print(f\"OLS MSE:\\t{ols_mse}\")\n",
    "print(f\"Ridge MSE:\\t{ridge_mse}\")\n",
    "print(f\"FFNN MSE:\\t{ffnn_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam: Eta=0.001, Lambda=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [=======================================>] 100.0% | train_error: 0.876 Adam: Eta=0.001, Lambda=0.0001\n",
      "  [=======================================>] 100.0% | train_error: 0.186   \n",
      "Output Franke Function:\n",
      "OLS MSE:\t0.0026093433625198996\n",
      "Ridge MSE:\t0.0035740018146377716\n",
      "FFNN MSE:\t0.3396722818637746\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Franke Function\n",
    "import autograd.numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "# Franke function\n",
    "def franke_function(x, y):\n",
    "    term1 = 0.75 * np.exp(-( (9*x - 2)**2 / 4.0 + (9*y - 2)**2 / 4.0))\n",
    "    term2 = 0.75 * np.exp(-( (9*x + 1)**2 / 49.0 + (9*y + 1)**2 / 10.0))\n",
    "    term3 = 0.5 * np.exp(-( (9*x - 7)**2 / 4.0 + (9*y - 3)**2 / 4.0))\n",
    "    term4 = -0.2 * np.exp(-(9*x - 4)**2 - (9*y - 7)**2)\n",
    "    return np.ravel(term1 + term2 + term3 + term4)\n",
    "\n",
    "def create_X(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    l = int((n + 1) * (n + 2) / 2)  # Number of elements in beta\n",
    "    X = np.ones((N, l))\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        q = int((i) * (i + 1) / 2)\n",
    "        for k in range(i + 1):\n",
    "            X[:, q + k] = (x ** (i - k)) * (y**k)\n",
    "\n",
    "    return X\n",
    "\n",
    "step=0.05\n",
    "x = np.arange(0, 1, step)\n",
    "y = np.arange(0, 1, step)\n",
    "x, y = np.meshgrid(x, y)\n",
    "target = franke_function(x, y)\n",
    "target = target.reshape(target.shape[0], 1)\n",
    "\n",
    "poly_degree=5\n",
    "X = create_X(x, y, poly_degree)\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, target, test_size=0.2)\n",
    "\n",
    "input_nodes = X_train.shape[1]\n",
    "hidden_nodes1 = 500\n",
    "hidden_nodes2 = 250\n",
    "output_nodes = 1\n",
    "\n",
    "dims = (input_nodes, hidden_nodes1, hidden_nodes2, output_nodes)\n",
    "linear_regression = FFNN(dims, hidden_func=sigmoid, output_func=identity, cost_func=CostOLS, seed=2024)\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "\n",
    "scheduler = Adam(eta=1e-3, rho=0.9, rho2=0.999)\n",
    "# scheduler = Constant(eta=1e-3)\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler)\n",
    "\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler, lam=1e-4, epochs=5000)\n",
    "\n",
    "# OLS using Scikit-Learn\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train, t_train)\n",
    "ols_predictions = ols_model.predict(X_test)\n",
    "ols_mse = mean_squared_error(t_test, ols_predictions)\n",
    "\n",
    "# Ridge using Scikit-Learn\n",
    "ridge_model = Ridge(alpha=1e-4)\n",
    "ridge_model.fit(X_train, t_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(t_test, ridge_predictions)\n",
    "\n",
    "# FFNN predictions\n",
    "ffnn_predictions = linear_regression.predict(X_test)\n",
    "ffnn_mse = mean_squared_error(t_test, ffnn_predictions)\n",
    "\n",
    "print(f'\\nOutput Franke Function:')\n",
    "print(f\"OLS MSE:\\t{ols_mse}\")\n",
    "print(f\"Ridge MSE:\\t{ridge_mse}\")\n",
    "print(f\"FFNN MSE:\\t{ffnn_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Analysis (ReLu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: Eta=0.001, Lambda=0\n",
      "  [----------------------------------------] 1.000% | train_error: 1848920880030883473331057427760313351403776863682104005395542259616286574261413093995837284120885014469844171587845761319083393896948665849902381906175765024595176345479424715490041903710208 "
     ]
    },
    {
     "ename": "RuntimeWarning",
     "evalue": "overflow encountered in matmul",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeWarning\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m linear_regression\u001b[38;5;241m.\u001b[39mreset_weights() \u001b[38;5;66;03m# reset weights such that previous runs or reruns don't affect the weights\u001b[39;00m\n\u001b[1;32m     49\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m Constant(eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_regression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m linear_regression\u001b[38;5;241m.\u001b[39mreset_weights() \u001b[38;5;66;03m# reset weights such that previous runs or reruns don't affect the weights\u001b[39;00m\n\u001b[1;32m     53\u001b[0m scores \u001b[38;5;241m=\u001b[39m linear_regression\u001b[38;5;241m.\u001b[39mfit(X_train, t_train, scheduler, lam\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine-Learning-University-of-Oslo/Project2/FFNN_class.py:336\u001b[0m, in \u001b[0;36mFFNN.fit\u001b[0;34m(self, X, t, scheduler, batches, epochs, lam, X_val, t_val)\u001b[0m\n\u001b[1;32m    333\u001b[0m         t_batch \u001b[38;5;241m=\u001b[39m t[i \u001b[38;5;241m*\u001b[39m batch_size : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size, :]\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feedforward(X_batch)\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# reset schedulers for each epoch (some schedulers pass in this call)\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scheduler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschedulers_weight:\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine-Learning-University-of-Oslo/Project2/FFNN_class.py:560\u001b[0m, in \u001b[0;36mFFNN._backpropagate\u001b[0;34m(self, X, t, lam)\u001b[0m\n\u001b[1;32m    555\u001b[0m     delta_matrix \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m:, :] \u001b[38;5;241m@\u001b[39m delta_matrix\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    557\u001b[0m     )\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m hidden_derivative(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_matrices[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# calculate gradient\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m gradient_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ma_matrices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta_matrix\u001b[49m\n\u001b[1;32m    561\u001b[0m gradient_bias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(delta_matrix, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;241m1\u001b[39m, delta_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# regularization term\u001b[39;00m\n",
      "\u001b[0;31mRuntimeWarning\u001b[0m: overflow encountered in matmul"
     ]
    }
   ],
   "source": [
    "# Linear Regression Example\n",
    "np.random.seed(2024)\n",
    "\n",
    "import autograd.numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def SkrankeFunction(x, y):\n",
    "    return np.ravel(0 + 1*x + 2*y + 3*x**2 + 4*x*y + 5*y**2)\n",
    "\n",
    "def create_X(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    l = int((n + 1) * (n + 2) / 2)  # Number of elements in beta\n",
    "    X = np.ones((N, l))\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        q = int((i) * (i + 1) / 2)\n",
    "        for k in range(i + 1):\n",
    "            X[:, q + k] = (x ** (i - k)) * (y**k)\n",
    "\n",
    "    return X\n",
    "\n",
    "step=0.05\n",
    "x = np.arange(0, 1, step)\n",
    "y = np.arange(0, 1, step)\n",
    "x, y = np.meshgrid(x, y)\n",
    "target = SkrankeFunction(x, y)\n",
    "target = target.reshape(target.shape[0], 1)\n",
    "\n",
    "poly_degree=3\n",
    "X = create_X(x, y, poly_degree)\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, target, test_size=0.2)\n",
    "\n",
    "input_nodes = X_train.shape[1]\n",
    "hidden_nodes1 = 500\n",
    "hidden_nodes2 = 500\n",
    "output_nodes = 1\n",
    "\n",
    "dims = (input_nodes, hidden_nodes1, hidden_nodes2, output_nodes)\n",
    "linear_regression = FFNN(dims, hidden_func=RELU, output_func=identity, cost_func=CostOLS, seed=2024)\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "\n",
    "scheduler = Constant(eta=1e-3)\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler)\n",
    "\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler, lam=1e-4, epochs=1000)\n",
    "\n",
    "# OLS using Scikit-Learn\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train, t_train)\n",
    "ols_predictions = ols_model.predict(X_test)\n",
    "ols_mse = mean_squared_error(t_test, ols_predictions)\n",
    "\n",
    "# Ridge using Scikit-Learn\n",
    "ridge_model = Ridge(alpha=1e-4)\n",
    "ridge_model.fit(X_train, t_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(t_test, ridge_predictions)\n",
    "\n",
    "# FFNN predictions\n",
    "ffnn_predictions = linear_regression.predict(X_test)\n",
    "ffnn_mse = mean_squared_error(t_test, ffnn_predictions)\n",
    "\n",
    "print(f'\\nOutput Skranke Function:')\n",
    "print(f\"OLS MSE:\\t{ols_mse}\")\n",
    "print(f\"Ridge MSE:\\t{ridge_mse}\")\n",
    "print(f\"FFNN MSE:\\t{ffnn_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constant: Eta=0.001, Lambda=0\n",
      "  [----------------------------------------] 1.000% | train_error: 720201790321532322590640191051012010367869765238006496714900891975962597434648827457332128320663289043413246090625974752002716480032713992441962104043689939576735365476563715405256580631247409588484047450718191636289797557846016 "
     ]
    },
    {
     "ename": "RuntimeWarning",
     "evalue": "overflow encountered in matmul",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeWarning\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m linear_regression\u001b[38;5;241m.\u001b[39mreset_weights() \u001b[38;5;66;03m# reset weights such that previous runs or reruns don't affect the weights\u001b[39;00m\n\u001b[1;32m     54\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m Constant(eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_regression\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m linear_regression\u001b[38;5;241m.\u001b[39mreset_weights() \u001b[38;5;66;03m# reset weights such that previous runs or reruns don't affect the weights\u001b[39;00m\n\u001b[1;32m     58\u001b[0m scores \u001b[38;5;241m=\u001b[39m linear_regression\u001b[38;5;241m.\u001b[39mfit(X_train, t_train, scheduler, lam\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine-Learning-University-of-Oslo/Project2/FFNN_class.py:336\u001b[0m, in \u001b[0;36mFFNN.fit\u001b[0;34m(self, X, t, scheduler, batches, epochs, lam, X_val, t_val)\u001b[0m\n\u001b[1;32m    333\u001b[0m         t_batch \u001b[38;5;241m=\u001b[39m t[i \u001b[38;5;241m*\u001b[39m batch_size : (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size, :]\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feedforward(X_batch)\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# reset schedulers for each epoch (some schedulers pass in this call)\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scheduler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschedulers_weight:\n",
      "File \u001b[0;32m~/Documents/GitHub/Machine-Learning-University-of-Oslo/Project2/FFNN_class.py:556\u001b[0m, in \u001b[0;36mFFNN._backpropagate\u001b[0;34m(self, X, t, lam)\u001b[0m\n\u001b[1;32m    549\u001b[0m         delta_matrix \u001b[38;5;241m=\u001b[39m out_derivative(\n\u001b[1;32m    550\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_matrices[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    551\u001b[0m         ) \u001b[38;5;241m*\u001b[39m cost_func_derivative(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_matrices[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# delta terms for hidden layer\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    555\u001b[0m     delta_matrix \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 556\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[1;32m    557\u001b[0m     )\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m hidden_derivative(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz_matrices[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# calculate gradient\u001b[39;00m\n\u001b[1;32m    560\u001b[0m gradient_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_matrices[i][:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m delta_matrix\n",
      "\u001b[0;31mRuntimeWarning\u001b[0m: overflow encountered in matmul"
     ]
    }
   ],
   "source": [
    "# Linear Regression Franke Function\n",
    "import autograd.numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "# Franke function\n",
    "def franke_function(x, y):\n",
    "    term1 = 0.75 * np.exp(-( (9*x - 2)**2 / 4.0 + (9*y - 2)**2 / 4.0))\n",
    "    term2 = 0.75 * np.exp(-( (9*x + 1)**2 / 49.0 + (9*y + 1)**2 / 10.0))\n",
    "    term3 = 0.5 * np.exp(-( (9*x - 7)**2 / 4.0 + (9*y - 3)**2 / 4.0))\n",
    "    term4 = -0.2 * np.exp(-(9*x - 4)**2 - (9*y - 7)**2)\n",
    "    return np.ravel(term1 + term2 + term3 + term4)\n",
    "\n",
    "def create_X(x, y, n):\n",
    "    if len(x.shape) > 1:\n",
    "        x = np.ravel(x)\n",
    "        y = np.ravel(y)\n",
    "\n",
    "    N = len(x)\n",
    "    l = int((n + 1) * (n + 2) / 2)  # Number of elements in beta\n",
    "    X = np.ones((N, l))\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        q = int((i) * (i + 1) / 2)\n",
    "        for k in range(i + 1):\n",
    "            X[:, q + k] = (x ** (i - k)) * (y**k)\n",
    "\n",
    "    return X\n",
    "\n",
    "step=0.05\n",
    "x = np.arange(0, 1, step)\n",
    "y = np.arange(0, 1, step)\n",
    "x, y = np.meshgrid(x, y)\n",
    "target = franke_function(x, y)\n",
    "target = target.reshape(target.shape[0], 1)\n",
    "\n",
    "poly_degree=5\n",
    "X = create_X(x, y, poly_degree)\n",
    "\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, target, test_size=0.2)\n",
    "\n",
    "input_nodes = X_train.shape[1]\n",
    "hidden_nodes1 = 300\n",
    "hidden_nodes2 = 300\n",
    "output_nodes = 1\n",
    "\n",
    "dims = (input_nodes, hidden_nodes1, hidden_nodes2, output_nodes)\n",
    "linear_regression = FFNN(dims, hidden_func=RELU, output_func=identity, cost_func=CostOLS, seed=2024)\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "\n",
    "scheduler = Constant(eta=1e-3)\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler)\n",
    "\n",
    "linear_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "scores = linear_regression.fit(X_train, t_train, scheduler, lam=1e-4, epochs=2000)\n",
    "\n",
    "# OLS using Scikit-Learn\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train, t_train)\n",
    "ols_predictions = ols_model.predict(X_test)\n",
    "ols_mse = mean_squared_error(t_test, ols_predictions)\n",
    "\n",
    "# Ridge using Scikit-Learn\n",
    "ridge_model = Ridge(alpha=1e-4)\n",
    "ridge_model.fit(X_train, t_train)\n",
    "ridge_predictions = ridge_model.predict(X_test)\n",
    "ridge_mse = mean_squared_error(t_test, ridge_predictions)\n",
    "\n",
    "# FFNN predictions\n",
    "ffnn_predictions = linear_regression.predict(X_test)\n",
    "ffnn_mse = mean_squared_error(t_test, ffnn_predictions)\n",
    "\n",
    "print(f'\\nOutput Franke Function:')\n",
    "print(f\"OLS MSE:\\t{ols_mse}\")\n",
    "print(f\"Ridge MSE:\\t{ridge_mse}\")\n",
    "print(f\"FFNN MSE:\\t{ffnn_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam: Eta=0.001, Lambda=0\n",
      "  [=======================================>] 100.0% | train_error: 3.79 | train_acc: 0.817 | val_error: 3.62 | val_acc: 0.825  Adam: Eta=0.0001, Lambda=0\n",
      "  [=======================================>] 100.0% | train_error: 0.146 | train_acc: 0.993 | val_error: 1.30 | val_acc: 0.937 "
     ]
    }
   ],
   "source": [
    "# Binary classification\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from FFNN_class import *\n",
    "\n",
    "wisconsin = load_breast_cancer()\n",
    "X = wisconsin.data\n",
    "target = wisconsin.target\n",
    "target = target.reshape(target.shape[0], 1)\n",
    "\n",
    "X_train, X_val, t_train, t_val = train_test_split(X, target)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "input_nodes = X_train.shape[1]\n",
    "output_nodes = 1\n",
    "\n",
    "logistic_regression = FFNN((input_nodes, output_nodes), output_func=sigmoid, cost_func=CostLogReg, seed=2023)\n",
    "\n",
    "logistic_regression.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "\n",
    "scheduler = Adam(eta=1e-3, rho=0.9, rho2=0.999)\n",
    "scores = logistic_regression.fit(X_train, t_train, scheduler, epochs=1000, X_val=X_val, t_val=t_val)\n",
    "\n",
    "input_nodes = X_train.shape[1]\n",
    "hidden_nodes1 = 100\n",
    "hidden_nodes2 = 30\n",
    "output_nodes = 1\n",
    "\n",
    "dims = (input_nodes, hidden_nodes1, hidden_nodes2, output_nodes)\n",
    "\n",
    "neural_network = FFNN(dims, hidden_func=RELU, output_func=sigmoid, cost_func=CostLogReg, seed=2023)\n",
    "\n",
    "neural_network.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "\n",
    "scheduler = Adam(eta=1e-4, rho=0.9, rho2=0.999)\n",
    "scores = neural_network.fit(X_train, t_train, scheduler, epochs=1000, X_val=X_val, t_val=t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "DeprecationWarning",
     "evalue": "backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeprecationWarning\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Plot the correlation heatmap\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(correlation_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m\"\u001b[39m, square\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Correlation Map\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/pyplot.py:934\u001b[0m, in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allnums) \u001b[38;5;241m==\u001b[39m max_open_warning \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    925\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_external(\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_open_warning\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m figures have been opened. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    927\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigures created through the pyplot interface \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using `matplotlib.pyplot.close()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[0;32m--> 934\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframeon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframeon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFigureClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m fig \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fig_label:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/pyplot.py:465\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new figure manager instance.\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/matplotlib_inline/backend_inline.py:27\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(num, FigureClass, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_figure_manager\u001b[39m(num, \u001b[38;5;241m*\u001b[39margs, FigureClass\u001b[38;5;241m=\u001b[39mFigure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Return a new figure manager for a new figure instance.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    This function is part of the API expected by Matplotlib backends.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_figure_manager_given_figure(num, \u001b[43mFigureClass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/figure.py:2578\u001b[0m, in \u001b[0;36mFigure.__init__\u001b[0;34m(self, figsize, dpi, facecolor, edgecolor, linewidth, frameon, subplotpars, tight_layout, constrained_layout, layout, **kwargs)\u001b[0m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_artist_props(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mset_antialiased(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 2578\u001b[0m \u001b[43mFigureCanvasBase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Set self.canvas.\u001b[39;00m\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subplotpars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2581\u001b[0m     subplotpars \u001b[38;5;241m=\u001b[39m SubplotParams()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/backend_bases.py:1721\u001b[0m, in \u001b[0;36mFigureCanvasBase.__init__\u001b[0;34m(self, figure)\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfigure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Figure\n\u001b[0;32m-> 1721\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fix_ipython_backend2gui\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_saving \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/backend_bases.py:1758\u001b[0m, in \u001b[0;36mFigureCanvasBase._fix_ipython_backend2gui\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[0;32m-> 1758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend2gui\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1759\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ip, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_matplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m   1760\u001b[0m     \u001b[38;5;66;03m# In case we ever move the patch to IPython and remove these APIs,\u001b[39;00m\n\u001b[1;32m   1761\u001b[0m     \u001b[38;5;66;03m# don't break on our side.\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m backend2gui_rif \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1764\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtk3\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtk3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1768\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacosx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mosx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1769\u001b[0m }\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mrequired_interactive_framework)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:77\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend2gui\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 77\u001b[0m         \u001b[43mwarnings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m is deprecated since IPython 8.24, backends are managed \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43min matplotlib and can be externally registered.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;167;43;01mDeprecationWarning\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_deprecated_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mDeprecationWarning\u001b[0m: backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered."
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert data to DataFrame for correlation calculation\n",
    "df = pd.DataFrame(X, columns=wisconsin.feature_names)\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Feature Correlation Map\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "DeprecationWarning",
     "evalue": "backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeprecationWarning\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m nn_preds \u001b[38;5;241m=\u001b[39m neural_network\u001b[38;5;241m.\u001b[39mpredict(X_val)\u001b[38;5;241m.\u001b[39mround()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Confusion matrices for both models\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Logistic Regression Confusion Matrix\u001b[39;00m\n\u001b[1;32m     12\u001b[0m cm_log_reg \u001b[38;5;241m=\u001b[39m confusion_matrix(t_val, log_reg_preds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/pyplot.py:1598\u001b[0m, in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msubplots\u001b[39m(\n\u001b[1;32m   1445\u001b[0m     nrows: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, ncols: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   1446\u001b[0m     sharex: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfig_kw\n\u001b[1;32m   1454\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[Figure, Any]:\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;124;03m    Create a figure and a set of subplots.\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1596\u001b[0m \n\u001b[1;32m   1597\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1598\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[43mfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfig_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1599\u001b[0m     axs \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39msubplots(nrows\u001b[38;5;241m=\u001b[39mnrows, ncols\u001b[38;5;241m=\u001b[39mncols, sharex\u001b[38;5;241m=\u001b[39msharex, sharey\u001b[38;5;241m=\u001b[39msharey,\n\u001b[1;32m   1600\u001b[0m                        squeeze\u001b[38;5;241m=\u001b[39msqueeze, subplot_kw\u001b[38;5;241m=\u001b[39msubplot_kw,\n\u001b[1;32m   1601\u001b[0m                        gridspec_kw\u001b[38;5;241m=\u001b[39mgridspec_kw, height_ratios\u001b[38;5;241m=\u001b[39mheight_ratios,\n\u001b[1;32m   1602\u001b[0m                        width_ratios\u001b[38;5;241m=\u001b[39mwidth_ratios)\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/pyplot.py:934\u001b[0m, in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(allnums) \u001b[38;5;241m==\u001b[39m max_open_warning \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    925\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_external(\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_open_warning\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m figures have been opened. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    927\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFigures created through the pyplot interface \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using `matplotlib.pyplot.close()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    932\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[0;32m--> 934\u001b[0m manager \u001b[38;5;241m=\u001b[39m \u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframeon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframeon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mFigureClass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFigureClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m fig \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fig_label:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/pyplot.py:465\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create a new figure manager instance.\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_figure_manager\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/matplotlib_inline/backend_inline.py:27\u001b[0m, in \u001b[0;36mnew_figure_manager\u001b[0;34m(num, FigureClass, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_figure_manager\u001b[39m(num, \u001b[38;5;241m*\u001b[39margs, FigureClass\u001b[38;5;241m=\u001b[39mFigure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Return a new figure manager for a new figure instance.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    This function is part of the API expected by Matplotlib backends.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_figure_manager_given_figure(num, \u001b[43mFigureClass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/figure.py:2578\u001b[0m, in \u001b[0;36mFigure.__init__\u001b[0;34m(self, figsize, dpi, facecolor, edgecolor, linewidth, frameon, subplotpars, tight_layout, constrained_layout, layout, **kwargs)\u001b[0m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_artist_props(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[1;32m   2576\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mset_antialiased(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 2578\u001b[0m \u001b[43mFigureCanvasBase\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Set self.canvas.\u001b[39;00m\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subplotpars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2581\u001b[0m     subplotpars \u001b[38;5;241m=\u001b[39m SubplotParams()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/backend_bases.py:1721\u001b[0m, in \u001b[0;36mFigureCanvasBase.__init__\u001b[0;34m(self, figure)\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfigure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Figure\n\u001b[0;32m-> 1721\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fix_ipython_backend2gui\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_saving \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/backend_bases.py:1758\u001b[0m, in \u001b[0;36mFigureCanvasBase._fix_ipython_backend2gui\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[0;32m-> 1758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend2gui\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1759\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ip, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable_matplotlib\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m   1760\u001b[0m     \u001b[38;5;66;03m# In case we ever move the patch to IPython and remove these APIs,\u001b[39;00m\n\u001b[1;32m   1761\u001b[0m     \u001b[38;5;66;03m# don't break on our side.\u001b[39;00m\n\u001b[1;32m   1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m backend2gui_rif \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1764\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtk3\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgtk3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1768\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacosx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mosx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1769\u001b[0m }\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mrequired_interactive_framework)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/IPython/core/pylabtools.py:77\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend2gui\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 77\u001b[0m         \u001b[43mwarnings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m is deprecated since IPython 8.24, backends are managed \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43min matplotlib and can be externally registered.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;167;43;01mDeprecationWarning\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_deprecated_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mDeprecationWarning\u001b[0m: backend2gui is deprecated since IPython 8.24, backends are managed in matplotlib and can be externally registered."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict on the validation set\n",
    "log_reg_preds = logistic_regression.predict(X_val).round()\n",
    "nn_preds = neural_network.predict(X_val).round()\n",
    "\n",
    "# Confusion matrices for both models\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Logistic Regression Confusion Matrix\n",
    "cm_log_reg = confusion_matrix(t_val, log_reg_preds)\n",
    "ConfusionMatrixDisplay(cm_log_reg).plot(ax=ax[0], cmap=\"Blues\")\n",
    "ax[0].set_title(\"Logistic Regression - Confusion Matrix\")\n",
    "\n",
    "# Neural Network Confusion Matrix\n",
    "cm_nn = confusion_matrix(t_val, nn_preds)\n",
    "ConfusionMatrixDisplay(cm_nn).plot(ax=ax[1], cmap=\"Purples\")\n",
    "ax[1].set_title(\"Neural Network - Confusion Matrix\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print accuracy for both models\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(t_val, log_reg_preds):.2f}\")\n",
    "print(f\"Neural Network Accuracy: {accuracy_score(t_val, nn_preds):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass classification\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "def onehot(target: np.ndarray):\n",
    "    onehot = np.zeros((target.size, target.max() + 1))\n",
    "    onehot[np.arange(target.size), target] = 1\n",
    "    return onehot\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.data\n",
    "target = digits.target\n",
    "target = onehot(target)\n",
    "\n",
    "input_nodes = 64\n",
    "hidden_nodes1 = 100\n",
    "hidden_nodes2 = 30\n",
    "output_nodes = 10\n",
    "\n",
    "dims = (input_nodes, hidden_nodes1, hidden_nodes2, output_nodes)\n",
    "\n",
    "multiclass = FFNN(dims, hidden_func=LRELU, output_func=softmax, cost_func=CostCrossEntropy)\n",
    "\n",
    "multiclass.reset_weights() # reset weights such that previous runs or reruns don't affect the weights\n",
    "\n",
    "scheduler = Adam(eta=1e-4, rho=0.9, rho2=0.999)\n",
    "scores = multiclass.fit(X, target, scheduler, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
