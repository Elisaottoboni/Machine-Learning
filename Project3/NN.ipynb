{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: /Users/gabrieledurante/.cache/kagglehub/datasets/fmena14/volcanoesvenus/versions/1\n",
      "['Volcanoes_train', 'Volcanoes_test']\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"fmena14/volcanoesvenus\")\n",
    "files = os.listdir(path)\n",
    "\n",
    "print(\"Path:\", path)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv(os.path.join(path, 'volcanoes_train', 'train_images.csv'))\n",
    "y_train = pd.read_csv(os.path.join(path, 'volcanoes_train', 'train_labels.csv'))\n",
    "X_test = pd.read_csv(os.path.join(path, 'volcanoes_test', 'test_images.csv'))\n",
    "y_test = pd.read_csv(os.path.join(path, 'volcanoes_test', 'test_labels.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XFix(X):\n",
    "    X.loc[-1] = X.columns.values.astype(float).astype(int)  # adding column names as a new row\n",
    "    X.index = X.index + 1  # shifting index\n",
    "    X.sort_index(inplace=True)  # sorting the index\n",
    "\n",
    "XFix(X_train)\n",
    "XFix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:\t (7000, 12100) \n",
      "y_train shape:\t (7000, 4) \n",
      "X_test shape:\t (2734, 12100) \n",
      "y_test shape:\t (2734, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\\t\",X_train.shape,\"\\ny_train shape:\\t\",y_train.shape,\"\\nX_test shape:\\t\",X_test.shape,\"\\ny_test shape:\\t\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[\"Volcano?\"]\n",
    "y_test = y_test[\"Volcano?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.astype(np.float32)\n",
    "y_train = y_train.values.astype(np.int64)\n",
    "X_test = X_test.values.astype(np.float32)\n",
    "y_test = y_test.values.astype(np.int64)\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\n",
    "y_train = to_categorical(y_train, num_classes = 2)\n",
    "y_test = to_categorical(y_test, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "# from torchvision import transforms\n",
    "# in this case, we dont have to transform images in tensor because we have images in csv\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class VolcanoDataset(Dataset):\n",
    "   def __init__ (self, images, labels):\n",
    "      self.images = torch.tensor(images, dtype = torch.float64)\n",
    "      self.labels = torch.tensor(labels, dtype = torch.float64)\n",
    "      \n",
    "   def __len__(self):\n",
    "      return len(self.images)\n",
    "   \n",
    "   def __getitem__(self, idx):\n",
    "      return self.images[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = VolcanoDataset(X_train, y_train)\n",
    "test_dataset = VolcanoDataset(X_test, y_test)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle= True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=12100, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# NN model\n",
    "import torch.nn as nn\n",
    "\n",
    "hidden_units = [64, 32]\n",
    "input_size = X_train.shape[1] # 12100 (110x110)\n",
    "output_size = len(np.unique(y_train))\n",
    "\n",
    "all_layers = []\n",
    "for hidden_unit in hidden_units:\n",
    "   all_layers.append(nn.Linear(input_size, hidden_unit))\n",
    "   all_layers.append(nn.ReLU())\n",
    "   input_size = hidden_unit # Update input_size for the next layer\n",
    "   \n",
    "all_layers.append(nn.Linear(hidden_units[-1], output_size))  # Final layer\n",
    "\n",
    "model = nn.Sequential(*all_layers)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.0886, Accuracy: 0.9807\n",
      "Epoch 2/25, Loss: 0.0692, Accuracy: 0.9834\n",
      "Epoch 3/25, Loss: 0.3414, Accuracy: 0.8969\n",
      "Epoch 4/25, Loss: 0.4051, Accuracy: 0.8571\n",
      "Epoch 5/25, Loss: 0.1739, Accuracy: 0.9444\n",
      "Epoch 6/25, Loss: 0.1998, Accuracy: 0.9563\n",
      "Epoch 7/25, Loss: 0.0940, Accuracy: 0.9789\n",
      "Epoch 8/25, Loss: 0.0616, Accuracy: 0.9877\n",
      "Epoch 9/25, Loss: 0.0657, Accuracy: 0.9844\n",
      "Epoch 10/25, Loss: 0.0660, Accuracy: 0.9844\n",
      "Epoch 11/25, Loss: 0.4084, Accuracy: 0.8764\n",
      "Epoch 12/25, Loss: 0.0892, Accuracy: 0.9804\n",
      "Epoch 13/25, Loss: 0.0542, Accuracy: 0.9899\n",
      "Epoch 14/25, Loss: 0.0988, Accuracy: 0.9750\n",
      "Epoch 15/25, Loss: 0.0558, Accuracy: 0.9884\n",
      "Epoch 16/25, Loss: 0.2027, Accuracy: 0.9397\n",
      "Epoch 17/25, Loss: 0.0769, Accuracy: 0.9823\n",
      "Epoch 18/25, Loss: 0.0807, Accuracy: 0.9809\n",
      "Epoch 19/25, Loss: 0.1513, Accuracy: 0.9616\n",
      "Epoch 20/25, Loss: 0.0758, Accuracy: 0.9809\n",
      "Epoch 21/25, Loss: 0.0533, Accuracy: 0.9884\n",
      "Epoch 22/25, Loss: 0.2051, Accuracy: 0.9470\n",
      "Epoch 23/25, Loss: 0.0725, Accuracy: 0.9846\n",
      "Epoch 24/25, Loss: 0.0996, Accuracy: 0.9720\n",
      "Epoch 25/25, Loss: 0.0618, Accuracy: 0.9840\n",
      "Accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def train_model(model, train_loader, epochs=25, device=None):\n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device).float()  # Ensure images are float32 and on the correct device\n",
    "            labels = labels.to(device).long()  # Ensure labels are long and on the correct device\n",
    "\n",
    "            # Convert one-hot encoded labels to class indices\n",
    "            if labels.dim() == 2:  # Check if labels are one-hot encoded\n",
    "                labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = loss_fn(outputs, labels)  # Compute loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct_preds / total_preds\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "    \n",
    "    accuracy = correct_preds / total_preds\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "train_model(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.0820, Accuracy: 0.9533\n",
      "Epoch 2/25, Loss: 0.0837, Accuracy: 0.9580\n",
      "Epoch 3/25, Loss: 0.1341, Accuracy: 0.9206\n",
      "Epoch 4/25, Loss: 0.0633, Accuracy: 0.9689\n",
      "Epoch 5/25, Loss: 0.2527, Accuracy: 0.8491\n",
      "Epoch 6/25, Loss: 0.1258, Accuracy: 0.9239\n",
      "Epoch 7/25, Loss: 0.0821, Accuracy: 0.9526\n",
      "Epoch 8/25, Loss: 0.0714, Accuracy: 0.9671\n",
      "Epoch 9/25, Loss: 0.1414, Accuracy: 0.9203\n",
      "Epoch 10/25, Loss: 0.0703, Accuracy: 0.9680\n",
      "Epoch 11/25, Loss: 0.1549, Accuracy: 0.9239\n",
      "Epoch 12/25, Loss: 0.0678, Accuracy: 0.9653\n",
      "Epoch 13/25, Loss: 0.0588, Accuracy: 0.9739\n",
      "Epoch 14/25, Loss: 0.0655, Accuracy: 0.9669\n",
      "Epoch 15/25, Loss: 0.2891, Accuracy: 0.8246\n",
      "Epoch 16/25, Loss: 0.3678, Accuracy: 0.7333\n",
      "Epoch 17/25, Loss: 0.0997, Accuracy: 0.9516\n",
      "Epoch 18/25, Loss: 0.1094, Accuracy: 0.9397\n",
      "Epoch 19/25, Loss: 0.1648, Accuracy: 0.9069\n",
      "Epoch 20/25, Loss: 0.0927, Accuracy: 0.9537\n",
      "Epoch 21/25, Loss: 0.0633, Accuracy: 0.9704\n",
      "Epoch 22/25, Loss: 0.2390, Accuracy: 0.8610\n",
      "Epoch 23/25, Loss: 0.0888, Accuracy: 0.9583\n",
      "Epoch 24/25, Loss: 0.0653, Accuracy: 0.9707\n",
      "Epoch 25/25, Loss: 0.0717, Accuracy: 0.9631\n",
      "Accuracy: 0.9631\n"
     ]
    }
   ],
   "source": [
    "# BCEWithLogitsLoss for binary classification\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "def train_model(model, train_loader, epochs=25, device=None):\n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()  # Apply sigmoid and threshold at 0.5\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = (correct_preds / len(train_loader.dataset)) -1   # Calculate accuracy as fraction of total dataset\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "    \n",
    "    accuracy = (correct_preds / len(train_loader.dataset)) - 1\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "train_model(model, train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
